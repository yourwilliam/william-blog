---
layout: post
title: Openstack 虚拟化优化方向
description: "Openstack虚拟化差异化优化方向"
modified: 2014-08-26
category: articles
tags: [Openstack]
comments: true
share: true
---

## 虚拟机亲和性调度机制
用于部分应用需要和某些指定应用隔离的场景，如主备场景等。

## 应用感知的大页表技术
用于高性能场景，使用大页表技术提供更高的内存hit率。

## 智能网络包中断合并技术

Linux内核在性能方面已经经历了很长一段时间的考验，尤其是2.6/3.x内核。然而，在高IO，尤其是网络方面的情况下，对中断的处理可能成为问题。我们已经在拥有一个或多个饱和1Gbps网卡的高性能系统上发现过这个问题，近来在有许多小包并发（大约10000packets/second）超载的虚拟机上也发现了这个问题。

原因很清楚：在最简单的模式中，内核通过硬件中断的方式来处理每个来自于网卡的包。但是随着数据包速率的增长，带来的中断渐渐超过了单个cpu可处理的范围。单cpu概念很重要，系统管理员对此往往认识不足。在一个普通的4-16核的系统中，因为整体cpu的使用率在6-25%左右并且系统看上去很正常，所以一个过载的内核很难被发现，。但是系统将运行很慢，并且会在没有告警，没有dmesg日志，没有明显征兆的情况下严重丢包。

详细内容请参考[技术项目 - Linux网卡中断使单个CPU过载](http://blog.csdn.net/chinanetcloud/article/details/8072455)



## 减少VM－Exit上下文等虚拟化性能敏感的指令的优化： 减少虚拟化开销，让cpu更多的做业务相关的事情

## 亲和性感知的调度，HOST/Guest NUMA 的配置调优

## NetMap/DPDK软直通，及SR-IOV／VMDq硬直通，实现转发能力5－10倍以上的提升。

## 轻量化的Linux容器技术： LXC 完全不使用硬件虚拟化，在host里面使用资源隔离技术，而不是做虚拟机级别的重隔离。